{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-04-27T07:30:49.354104Z","iopub.execute_input":"2022-04-27T07:30:49.354727Z","iopub.status.idle":"2022-04-27T07:30:49.380397Z","shell.execute_reply.started":"2022-04-27T07:30:49.354627Z","shell.execute_reply":"2022-04-27T07:30:49.379659Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport nltk \nnltk.download('stopwords')\nnltk.download('wordnet')","metadata":{"execution":{"iopub.status.busy":"2022-04-27T07:30:50.013741Z","iopub.execute_input":"2022-04-27T07:30:50.014196Z","iopub.status.idle":"2022-04-27T07:30:51.731625Z","shell.execute_reply.started":"2022-04-27T07:30:50.014161Z","shell.execute_reply":"2022-04-27T07:30:51.730938Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# load the data\ndata = pd.read_csv(\"/kaggle/input/fake-news/train.csv\")\ndata.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-27T07:30:51.733499Z","iopub.execute_input":"2022-04-27T07:30:51.733771Z","iopub.status.idle":"2022-04-27T07:30:54.039519Z","shell.execute_reply.started":"2022-04-27T07:30:51.733736Z","shell.execute_reply":"2022-04-27T07:30:54.038746Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"print(\"Shape of dataset \", data.shape)\nprint(\"Columns \", data.columns)","metadata":{"execution":{"iopub.status.busy":"2022-04-27T07:30:54.040947Z","iopub.execute_input":"2022-04-27T07:30:54.041446Z","iopub.status.idle":"2022-04-27T07:30:54.047646Z","shell.execute_reply.started":"2022-04-27T07:30:54.041390Z","shell.execute_reply":"2022-04-27T07:30:54.046863Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# Let's do some statistics of the text columns\ntxt_len = data.text.str.split().str.len()\ntxt_len.describe()","metadata":{"execution":{"iopub.status.busy":"2022-04-27T07:30:54.049936Z","iopub.execute_input":"2022-04-27T07:30:54.050225Z","iopub.status.idle":"2022-04-27T07:30:56.413063Z","shell.execute_reply.started":"2022-04-27T07:30:54.050169Z","shell.execute_reply":"2022-04-27T07:30:56.411306Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# Let's do some statistics of the title columns\ntitle_len = data.title.str.split().str.len()\ntitle_len.describe()","metadata":{"execution":{"iopub.status.busy":"2022-04-27T07:30:56.414367Z","iopub.execute_input":"2022-04-27T07:30:56.414734Z","iopub.status.idle":"2022-04-27T07:30:56.781376Z","shell.execute_reply.started":"2022-04-27T07:30:56.414691Z","shell.execute_reply":"2022-04-27T07:30:56.780495Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# Class Distribution\n# 1: Unreliable\n# 2: Reliable\nsns.countplot(x='label', data= data)","metadata":{"execution":{"iopub.status.busy":"2022-04-27T07:30:56.782795Z","iopub.execute_input":"2022-04-27T07:30:56.783149Z","iopub.status.idle":"2022-04-27T07:30:56.985434Z","shell.execute_reply.started":"2022-04-27T07:30:56.783108Z","shell.execute_reply":"2022-04-27T07:30:56.984718Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"print(data.label.value_counts())\nprint()\nprint(round(data.label.value_counts(normalize=True),2)*100)","metadata":{"execution":{"iopub.status.busy":"2022-04-27T07:30:56.987788Z","iopub.execute_input":"2022-04-27T07:30:56.988244Z","iopub.status.idle":"2022-04-27T07:30:56.999484Z","shell.execute_reply.started":"2022-04-27T07:30:56.988201Z","shell.execute_reply":"2022-04-27T07:30:56.998652Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"### Data Cleaning \n\n- Drop unused rows and columns.\n- Perform null value imputation.\n- Remove special characters.\n- Remove stop words.","metadata":{}},{"cell_type":"code","source":"data.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2022-04-27T07:30:57.001998Z","iopub.execute_input":"2022-04-27T07:30:57.002580Z","iopub.status.idle":"2022-04-27T07:30:57.022312Z","shell.execute_reply.started":"2022-04-27T07:30:57.002541Z","shell.execute_reply":"2022-04-27T07:30:57.021593Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"column_n = ['id', 'title', 'author', 'text', 'label']\nremove_c = ['id','author']\ncategorical_features = []\ntarget_col = ['label']\ntext_f = ['title', 'text']","metadata":{"execution":{"iopub.status.busy":"2022-04-27T07:30:57.023330Z","iopub.execute_input":"2022-04-27T07:30:57.024038Z","iopub.status.idle":"2022-04-27T07:30:57.029477Z","shell.execute_reply.started":"2022-04-27T07:30:57.024001Z","shell.execute_reply":"2022-04-27T07:30:57.028353Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# cleaning\nimport nltk\nfrom nltk.corpus import stopwords\nimport re\nfrom nltk.stem.porter import PorterStemmer\nfrom collections import Counter\n\nps = PorterStemmer()\nwnl = nltk.stem.WordNetLemmatizer()\n\nstop_words = stopwords.words('english')\nstopwords_dict = Counter(stop_words)\n\n# remove unused columns\ndef remove_unused_c(df, column_n=remove_c):\n    df = df.drop(column_n, axis=1)\n    return df\n\n# impute null values with none\ndef null_process(feature_df):\n    for col in text_f:\n        feature_df.loc[feature_df[col].isnull(),col] = \"None\"\n    return feature_df\n\n# clean_data\ndef clean_dataset(df):\n    # remove unused column\n    df = remove_unused_c(df)    \n    #impute null value\n    df = null_process(df)\n    \n    return df\n\n# Cleaning text from unused characters\ndef clean_text(text):\n    text = str(text).replace(r'http[\\w:/\\.]+', ' ')  # removing urls\n    text = str(text).replace(r'[^\\.\\w\\s]', ' ')  # remove everything but characters and punctuation\n    text = str(text).replace('[^a-zA-Z]', ' ')\n    text = str(text).replace(r'\\s\\s+', ' ')\n    text = text.lower().strip()\n    #text = ' '.join(text)    \n    return text\n\n## Nltk Preprocessing include:\n# Stop words, Stemming and Lemmetization\n# For our project we use only Stop word removal\ndef nltk_preprocess(text):\n    text = clean_text(text)\n    wordlist = re.sub(r'[^\\w\\s]', '', text).split()\n    text = ' '.join([wnl.lemmatize(word) for word in wordlist if word not in stopwords_dict])\n    return  text","metadata":{"execution":{"iopub.status.busy":"2022-04-27T07:30:57.030826Z","iopub.execute_input":"2022-04-27T07:30:57.031575Z","iopub.status.idle":"2022-04-27T07:30:57.046602Z","shell.execute_reply.started":"2022-04-27T07:30:57.031540Z","shell.execute_reply":"2022-04-27T07:30:57.045847Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"df = clean_dataset(data)\ndf['text'] = df.text.apply(nltk_preprocess)\ndf['title'] = df.title.apply(nltk_preprocess)","metadata":{"execution":{"iopub.status.busy":"2022-04-27T07:30:57.183616Z","iopub.execute_input":"2022-04-27T07:30:57.183864Z","iopub.status.idle":"2022-04-27T07:31:53.586580Z","shell.execute_reply.started":"2022-04-27T07:30:57.183837Z","shell.execute_reply":"2022-04-27T07:31:53.585780Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-27T07:31:53.588328Z","iopub.execute_input":"2022-04-27T07:31:53.588586Z","iopub.status.idle":"2022-04-27T07:31:53.598608Z","shell.execute_reply.started":"2022-04-27T07:31:53.588553Z","shell.execute_reply":"2022-04-27T07:31:53.597607Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"### EDA \n- Univariate Analysis :- It is a statistical analysis of the text. We will use word cloud for that purpose. A word cloud is a visualization approach for text data where the most common term is presented in the most considerable font size.\n- Bivariate Analysis :- Bigram and Trigram will be used here. According to Wikipedia: \"an n-gram is a contiguous sequence of n items from a given sample of text or speech. According to the application, the items can be phonemes, syllables, letters, words, or base pairs. The n-grams are typically collected from a text or speech corpus\".","metadata":{}},{"cell_type":"code","source":"from wordcloud import WordCloud, STOPWORDS\n\n# initialize the word cloud\nwordcloud = WordCloud(background_color='black', width=800, height=600)\n# generate the word cloud\ntext_cloud = wordcloud.generate(\" \".join(df['text']))\n# plotting the word cloud\nplt.figure(figsize=(20,30))\nplt.imshow(text_cloud)\nplt.axis('off')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-27T07:31:53.600790Z","iopub.execute_input":"2022-04-27T07:31:53.601304Z","iopub.status.idle":"2022-04-27T07:33:10.662301Z","shell.execute_reply.started":"2022-04-27T07:31:53.601266Z","shell.execute_reply":"2022-04-27T07:33:10.661527Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# reliable news (0)\nreliable_news = \" \".join(df[df['label']==0]['text'])\nwc = wordcloud.generate(reliable_news)\nplt.figure(figsize=(20,30))\nplt.imshow(wc)\nplt.axis('off')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-27T07:33:10.664109Z","iopub.execute_input":"2022-04-27T07:33:10.664323Z","iopub.status.idle":"2022-04-27T07:33:56.554847Z","shell.execute_reply.started":"2022-04-27T07:33:10.664295Z","shell.execute_reply":"2022-04-27T07:33:56.554083Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"# unreliable news (1)\nunreliable_news  = ' '.join(df[df['label']==1]['text'])\nwc= wordcloud.generate(unreliable_news)\nplt.figure(figsize=(20,30))\nplt.imshow(wc)\nplt.axis('off')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-27T07:33:56.555950Z","iopub.execute_input":"2022-04-27T07:33:56.556286Z","iopub.status.idle":"2022-04-27T07:34:30.616345Z","shell.execute_reply.started":"2022-04-27T07:33:56.556254Z","shell.execute_reply":"2022-04-27T07:34:30.612850Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"# Bigram \n\ndef plot_top_ngrams(corpus, title, ylabel, xlabel=\"Number of Occurenes\", n =2):\n    true_b = (pd.Series(nltk.ngrams(corpus.split(), n)).value_counts())[:20]\n    true_b.sort_values().plot.barh(color='blue', width=.9, figsize=(12,8))\n    plt.title(title)\n    plt.ylabel(ylabel)\n    plt.xlabel(xlabel)\n    plt.show()\n    \n    \nplot_top_ngrams(reliable_news, \"Top 20 Frequently Occuring True News Bigrams\", \"Bigram\", n=2)","metadata":{"execution":{"iopub.status.busy":"2022-04-27T07:34:30.617743Z","iopub.execute_input":"2022-04-27T07:34:30.618209Z","iopub.status.idle":"2022-04-27T07:34:42.906658Z","shell.execute_reply.started":"2022-04-27T07:34:30.618172Z","shell.execute_reply":"2022-04-27T07:34:42.905891Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"plot_top_ngrams(unreliable_news, 'Top 20 Frequently Occuring Fake news Bigrams', \"Bigram\", n=2)","metadata":{"execution":{"iopub.status.busy":"2022-04-27T07:34:42.907984Z","iopub.execute_input":"2022-04-27T07:34:42.908679Z","iopub.status.idle":"2022-04-27T07:34:51.745675Z","shell.execute_reply.started":"2022-04-27T07:34:42.908634Z","shell.execute_reply":"2022-04-27T07:34:51.744869Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"# Trigram\nplot_top_ngrams(reliable_news, \"Top 20 Frequently Occuring True News Bigrams\", \"Bigram\", n=3)","metadata":{"execution":{"iopub.status.busy":"2022-04-27T07:34:51.747157Z","iopub.execute_input":"2022-04-27T07:34:51.747582Z","iopub.status.idle":"2022-04-27T07:35:05.539103Z","shell.execute_reply.started":"2022-04-27T07:34:51.747542Z","shell.execute_reply":"2022-04-27T07:35:05.538234Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"plot_top_ngrams(unreliable_news, \"Top 20 Frequently Occuring True News Bigrams\", \"Bigram\", n=3)","metadata":{"execution":{"iopub.status.busy":"2022-04-27T07:35:05.540367Z","iopub.execute_input":"2022-04-27T07:35:05.541145Z","iopub.status.idle":"2022-04-27T07:35:15.782530Z","shell.execute_reply.started":"2022-04-27T07:35:05.541103Z","shell.execute_reply":"2022-04-27T07:35:15.781771Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":"## Classifier by Fine-tuning BERT","metadata":{}},{"cell_type":"code","source":"import torch\nfrom transformers.file_utils import is_tf_available, is_torch_available, is_torch_tpu_available\nfrom transformers import BertTokenizerFast, BertForSequenceClassification\nfrom transformers import Trainer, TrainingArguments\nfrom sklearn.model_selection import train_test_split\nimport random","metadata":{"execution":{"iopub.status.busy":"2022-04-27T07:35:15.785636Z","iopub.execute_input":"2022-04-27T07:35:15.787668Z","iopub.status.idle":"2022-04-27T07:35:21.223696Z","shell.execute_reply.started":"2022-04-27T07:35:15.787634Z","shell.execute_reply":"2022-04-27T07:35:21.222937Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"def set_seed(seed: int):\n    \"\"\"\n    Helper function for reproducible behavior to set the seed in ``random``, ``numpy``, ``torch`` and/or ``tf`` (if\n    installed).\n\n    Args:\n        seed (:obj:`int`): The seed to set.\n    \"\"\"\n    random.seed(seed)\n    np.random.seed(seed)\n    if is_torch_available():\n        torch.manual_seed(seed)\n        torch.cuda.manual_seed_all(seed)\n        # ^^ safe to call this function even if cuda is not available\n    if is_tf_available():\n        import tensorflow as tf\n\n        tf.random.set_seed(seed)\n\nset_seed(123)","metadata":{"execution":{"iopub.status.busy":"2022-04-27T07:35:21.225348Z","iopub.execute_input":"2022-04-27T07:35:21.225602Z","iopub.status.idle":"2022-04-27T07:35:21.234122Z","shell.execute_reply.started":"2022-04-27T07:35:21.225568Z","shell.execute_reply":"2022-04-27T07:35:21.233361Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"model_name = \"bert-base-uncased\"\nmax_length= 512","metadata":{"execution":{"iopub.status.busy":"2022-04-27T07:35:21.235586Z","iopub.execute_input":"2022-04-27T07:35:21.236026Z","iopub.status.idle":"2022-04-27T07:35:21.244207Z","shell.execute_reply.started":"2022-04-27T07:35:21.235985Z","shell.execute_reply":"2022-04-27T07:35:21.243345Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"tokenizer = BertTokenizerFast.from_pretrained(model_name, do_lower_case=True)","metadata":{"execution":{"iopub.status.busy":"2022-04-27T07:35:21.245762Z","iopub.execute_input":"2022-04-27T07:35:21.246095Z","iopub.status.idle":"2022-04-27T07:35:34.683208Z","shell.execute_reply.started":"2022-04-27T07:35:21.246057Z","shell.execute_reply":"2022-04-27T07:35:34.682481Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"data.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-27T07:35:34.684313Z","iopub.execute_input":"2022-04-27T07:35:34.685022Z","iopub.status.idle":"2022-04-27T07:35:34.698439Z","shell.execute_reply.started":"2022-04-27T07:35:34.684982Z","shell.execute_reply":"2022-04-27T07:35:34.697596Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"## Data Preparation\ndata = data[data['text'].notna()]\ndata = data[data['title'].notna()]\ndata = data[data['author'].notna()]","metadata":{"execution":{"iopub.status.busy":"2022-04-27T07:35:34.699983Z","iopub.execute_input":"2022-04-27T07:35:34.700681Z","iopub.status.idle":"2022-04-27T07:35:34.721410Z","shell.execute_reply.started":"2022-04-27T07:35:34.700641Z","shell.execute_reply":"2022-04-27T07:35:34.720824Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"\"\"\"\nNext, making a function that takes the dataset as a Pandas dataframe \nand returns the train/validation splits of texts and labels as lists:\n\"\"\"\ndef prepare_data(df, test_size=0.2, include_title=True, include_author=True):\n    texts = []\n    labels = []\n    \n    for i in range(len(df)):\n        text = df['text'].iloc[i]\n        label = df['label'].iloc[i]\n        \n        if include_title:\n            text = df['title'].iloc[i] + \" - \" + text\n        if include_author:\n            text = df['author'].iloc[i] + \" - \" + text\n        \n        if text and label in [0,1]:\n            texts.append(text)\n            labels.append(label)\n            \n    return train_test_split(texts, labels, test_size=test_size)\n\ntrain_texts, valid_texts, train_labels, valid_labels = prepare_data(data)","metadata":{"execution":{"iopub.status.busy":"2022-04-27T07:35:34.722614Z","iopub.execute_input":"2022-04-27T07:35:34.723327Z","iopub.status.idle":"2022-04-27T07:35:35.693947Z","shell.execute_reply.started":"2022-04-27T07:35:34.723289Z","shell.execute_reply":"2022-04-27T07:35:35.693266Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"print(len(train_texts), len(train_labels))\nprint(len(valid_texts), len(valid_labels))","metadata":{"execution":{"iopub.status.busy":"2022-04-27T07:35:35.695043Z","iopub.execute_input":"2022-04-27T07:35:35.695292Z","iopub.status.idle":"2022-04-27T07:35:35.701512Z","shell.execute_reply.started":"2022-04-27T07:35:35.695258Z","shell.execute_reply":"2022-04-27T07:35:35.700677Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"# tokenizing the dataset\ntrain_encodings = tokenizer(train_texts, truncation=True, padding=True, max_length=max_length)\nvalid_encodings = tokenizer(valid_texts, truncation=True, padding=True, max_length=max_length)","metadata":{"execution":{"iopub.status.busy":"2022-04-27T07:35:35.702869Z","iopub.execute_input":"2022-04-27T07:35:35.703534Z","iopub.status.idle":"2022-04-27T07:36:26.535766Z","shell.execute_reply.started":"2022-04-27T07:35:35.703495Z","shell.execute_reply":"2022-04-27T07:36:26.534890Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"# converting the encoding into a PyTorch datset\nclass NewsGroupsDataset(torch.utils.data.Dataset):\n    def __init__(self, encodings, labels):\n        self.encodings = encodings\n        self.labels = labels\n    \n    def __getitem__(self, idx):\n        item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n        item['labels'] = torch.tensor([self.labels[idx]])\n        return item\n    \n    def __len__(self):\n        return len(self.labels)\n    \n# convert tokenize data into torch dataset\ntrain_dataset = NewsGroupsDataset(train_encodings, train_labels)\nvalid_dataset = NewsGroupsDataset(valid_encodings, valid_labels)","metadata":{"execution":{"iopub.status.busy":"2022-04-27T07:36:26.537269Z","iopub.execute_input":"2022-04-27T07:36:26.537525Z","iopub.status.idle":"2022-04-27T07:36:26.546968Z","shell.execute_reply.started":"2022-04-27T07:36:26.537492Z","shell.execute_reply":"2022-04-27T07:36:26.544165Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"markdown","source":"### Loading and find-tuning the model","metadata":{}},{"cell_type":"code","source":"model = BertForSequenceClassification.from_pretrained(model_name, num_labels=2)","metadata":{"execution":{"iopub.status.busy":"2022-04-27T07:36:26.548376Z","iopub.execute_input":"2022-04-27T07:36:26.548858Z","iopub.status.idle":"2022-04-27T07:36:59.552975Z","shell.execute_reply.started":"2022-04-27T07:36:26.548818Z","shell.execute_reply":"2022-04-27T07:36:59.552238Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score\n\ndef computer_metrics(pred):\n    labels = pred.label_ids\n    preds = pred.predictions.argmax(-1)\n    acc = accuracy_score(labels, preds)\n    \n    return {'accuracy':acc,}","metadata":{"execution":{"iopub.status.busy":"2022-04-27T07:36:59.554482Z","iopub.execute_input":"2022-04-27T07:36:59.554922Z","iopub.status.idle":"2022-04-27T07:36:59.560304Z","shell.execute_reply.started":"2022-04-27T07:36:59.554866Z","shell.execute_reply":"2022-04-27T07:36:59.559236Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"training_args = TrainingArguments(\n    output_dir='./results',          # output directory\n    num_train_epochs=1,              # total number of training epochs\n    per_device_train_batch_size=10,  # batch size per device during training\n    per_device_eval_batch_size=20,   # batch size for evaluation\n    warmup_steps=100,                # number of warmup steps for learning rate scheduler\n    logging_dir='./logs',            # directory for storing logs\n    load_best_model_at_end=True,     # load the best model when finished training (default metric is loss)\n    # but you can specify `metric_for_best_model` argument to change to accuracy or other metric\n    logging_steps=200,               # log & save weights each logging_steps\n    save_steps=200,\n    evaluation_strategy=\"steps\",     # evaluate each `logging_steps`\n)","metadata":{"execution":{"iopub.status.busy":"2022-04-27T07:36:59.561759Z","iopub.execute_input":"2022-04-27T07:36:59.562062Z","iopub.status.idle":"2022-04-27T07:36:59.625683Z","shell.execute_reply.started":"2022-04-27T07:36:59.562025Z","shell.execute_reply":"2022-04-27T07:36:59.624951Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"trainer = Trainer(\n    model = model,\n    args = training_args,\n    train_dataset=train_dataset,\n    eval_dataset=valid_dataset,\n    compute_metrics=computer_metrics,\n)","metadata":{"execution":{"iopub.status.busy":"2022-04-27T07:36:59.627158Z","iopub.execute_input":"2022-04-27T07:36:59.627434Z","iopub.status.idle":"2022-04-27T07:37:05.203687Z","shell.execute_reply.started":"2022-04-27T07:36:59.627383Z","shell.execute_reply":"2022-04-27T07:37:05.202831Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"trainer.train()","metadata":{"execution":{"iopub.status.busy":"2022-04-27T07:37:05.205431Z","iopub.execute_input":"2022-04-27T07:37:05.205652Z","iopub.status.idle":"2022-04-27T08:05:17.571089Z","shell.execute_reply.started":"2022-04-27T07:37:05.205625Z","shell.execute_reply":"2022-04-27T08:05:17.570268Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"# evaluate the current model after training\ntrainer.evaluate()","metadata":{"execution":{"iopub.status.busy":"2022-04-27T08:05:53.259183Z","iopub.execute_input":"2022-04-27T08:05:53.259490Z","iopub.status.idle":"2022-04-27T08:06:59.762045Z","shell.execute_reply.started":"2022-04-27T08:05:53.259458Z","shell.execute_reply":"2022-04-27T08:06:59.761278Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"# saving the fine tuned model & tokenizer\nmodel_path = \"fake-news-bert-base-uncased\"\nmodel.save_pretrained(model_path)\ntokenizer.save_pretrained(model_path)","metadata":{"execution":{"iopub.status.busy":"2022-04-27T08:06:59.764039Z","iopub.execute_input":"2022-04-27T08:06:59.764677Z","iopub.status.idle":"2022-04-27T08:07:00.602862Z","shell.execute_reply.started":"2022-04-27T08:06:59.764635Z","shell.execute_reply":"2022-04-27T08:07:00.601947Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"def get_prediction(text, convert_to_label=False):\n    # prepare our text into tokenized sequence\n    inputs = tokenizer(text, padding=True, truncation=True, max_length=max_length, return_tensors=\"pt\").to(\"cuda\")\n    # perform inference to our model\n    outputs = model(**inputs)\n    # get output probabilities by doing softmax\n    probs = outputs[0].softmax(1)\n    # executing argmax function to get the candidate label\n    d = {\n        0: \"reliable\",\n        1: \"fake\"\n    }\n    if convert_to_label:\n        return d[int(probs.argmax())]\n    else:\n        return int(probs.argmax())","metadata":{"execution":{"iopub.status.busy":"2022-04-27T08:07:00.604320Z","iopub.execute_input":"2022-04-27T08:07:00.604958Z","iopub.status.idle":"2022-04-27T08:07:00.612566Z","shell.execute_reply.started":"2022-04-27T08:07:00.604901Z","shell.execute_reply":"2022-04-27T08:07:00.611745Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"real_news = \"\"\"\nTim Tebow Will Attempt Another Comeback, This Time in Baseball - The New York Times\",Daniel Victor,\"If at first you donâ€™t succeed, try a different sport. Tim Tebow, who was a Heisman   quarterback at the University of Florida but was unable to hold an N. F. L. job, is pursuing a career in Major League Baseball. <SNIPPED>\n\"\"\"\n\nget_prediction(real_news, convert_to_label=True)","metadata":{"execution":{"iopub.status.busy":"2022-04-27T08:07:00.614719Z","iopub.execute_input":"2022-04-27T08:07:00.615018Z","iopub.status.idle":"2022-04-27T08:07:00.675557Z","shell.execute_reply.started":"2022-04-27T08:07:00.614982Z","shell.execute_reply":"2022-04-27T08:07:00.674774Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"# read the test set\ntest_df = pd.read_csv(\"../input/fake-news/test.csv\")\n# make a copy of the testing set\nnew_df = test_df.copy()\n# add a new column that contains the author, title and article content\nnew_df[\"new_text\"] = new_df[\"author\"].astype(str) + \" : \" + new_df[\"title\"].astype(str) + \" - \" + new_df[\"text\"].astype(str)\n# get the prediction of all the test set\nnew_df[\"label\"] = new_df[\"new_text\"].apply(get_prediction)\n# make the submission file\nfinal_df = new_df[[\"id\", \"label\"]]\nfinal_df.to_csv(\"submit_final.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2022-04-27T08:07:41.989367Z","iopub.execute_input":"2022-04-27T08:07:41.989651Z","iopub.status.idle":"2022-04-27T08:09:42.458518Z","shell.execute_reply.started":"2022-04-27T08:07:41.989620Z","shell.execute_reply":"2022-04-27T08:09:42.457752Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}